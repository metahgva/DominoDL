{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77cad994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import ray\n",
    "import logging\n",
    "\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "    service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "    address=f\"ray://{service_host}:{service_port}\"\n",
    "    temp_dir='/mnt/data//{}/'.format(os.environ['DOMINO_PROJECT_NAME']) #set to a dataset\n",
    "    local = (os.environ['IS_MLFLOW_LOCAL']=='True')\n",
    "    if(local):\n",
    "        print('start ray locally')\n",
    "        ray.init()\n",
    "    else:    \n",
    "        ray.init(address=address, _temp_dir=temp_dir)\n",
    "else:\n",
    "    print('ray is initializied')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24cb54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7f9aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "local = (os.environ['IS_MLFLOW_LOCAL']=='True')\n",
    "print(local)\n",
    "print(os.environ['MLFLOW_TRACKING_URI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c2b13",
   "metadata": {},
   "source": [
    "## Define the Pytorch Lightning model based on MNIST dataset taken from the Pytorch Lightning tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a394b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0510 01:49:37.037759859     308 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0510 01:49:37.047815158     308 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0510 01:49:37.152706206     308 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "#from torchmetrics import MetricCollection, Accuracy, Precision, Recall\n",
    "\n",
    "class LightningMNISTClassifier(pl.LightningModule):\n",
    "    def __init__(self, config, data_dir=None):\n",
    "        super(LightningMNISTClassifier, self).__init__()\n",
    " \n",
    "        self.data_dir = data_dir or os.getcwd()\n",
    "        self.lr = config[\"lr\"]\n",
    "        layer_1, layer_2 = config[\"layer_1\"], config[\"layer_2\"]\n",
    " \n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        self.layer_1 = torch.nn.Linear(28 * 28, layer_1)\n",
    "        self.layer_2 = torch.nn.Linear(layer_1, layer_2)\n",
    "        self.layer_3 = torch.nn.Linear(layer_2, 10)\n",
    "        self.accuracy = pl.metrics.Accuracy()\n",
    " \n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.layer_1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x\n",
    " \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    " \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        acc = self.accuracy(logits, y)\n",
    "        self.log(\"ptl/train_loss\", loss)\n",
    "        self.log(\"ptl/train_accuracy\", acc)\n",
    "        return loss\n",
    " \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        acc = self.accuracy(logits, y)\n",
    "        return {\"val_loss\": loss, \"val_accuracy\": acc}\n",
    " \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"val_accuracy\"] for x in outputs]).mean()\n",
    "        self.log(\"ptl/val_loss\", avg_loss)\n",
    "        self.log(\"ptl/val_accuracy\", avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b8fd1",
   "metadata": {},
   "source": [
    "## Create Training Function and Log Model\n",
    "The main thing we have to do here is to add the mlflow_mixin decorator to our training function. Adding the decorator will allow us to call any mlflow.tracking methods inside the training function, and it will automatically log to the correct MLflow run.\n",
    "\n",
    "In this example, we can simply call mlflow.pytorch.autolog() before we start training. This will automatically log all of the metrics, parameters, and model artifacts of our Pytorch Lightning model without having to explicitly log them.\n",
    "\n",
    "We then use Ray Tune's inegration with Pytorch Lightning, the TuneReportCallback, so that when the model is training, intermediate results can be reported back to Tune.\n",
    "\n",
    "And the last thing we have to do is set the appropriate Domino credentials so that we can log to the MLFlow server from remote processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b99d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0510 01:49:38.162714138     308 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0510 01:49:38.188999721     308 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "2022-05-10 01:49:38,888\tWARNING mlflow.py:337 -- When using mlflow_mixin with Ray Client, it is recommended to use a remote tracking server. If you are using a MLflow tracking server backed by the local filesystem, then it must be setup on the server side and not on the client side.\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.datamodules.mnist_datamodule import MNISTDataModule\n",
    "from ray.tune.integration.mlflow import mlflow_mixin\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    " \n",
    "@mlflow_mixin\n",
    "def train_mnist_tune(config):\n",
    "    # AWS creds are needed for artifacts\n",
    "    os.environ['AWS_ACCESS_KEY_ID']=config['AWS_ACCESS_KEY_ID']\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS_SECRET_ACCESS_KEY']\n",
    "    \n",
    "    model = LightningMNISTClassifier(config, config[\"data_dir\"])\n",
    "    dm = MNISTDataModule(\n",
    "        data_dir=data_dir, num_workers=0, batch_size=config[\"batch_size\"])\n",
    "    metrics = {\"val_loss\": \"ptl/val_loss\", \"val_acc\": \"ptl/val_accuracy\"}\n",
    "    mlflow.pytorch.autolog()\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config[\"num_epochs\"],\n",
    "        gpus=config[\"num_gpus\"],\n",
    "        progress_bar_refresh_rate=0,\n",
    "        callbacks=[TuneReportCallback(metrics, on=\"validation_end\")])\n",
    "    trainer.fit(model, dm)\n",
    "    \n",
    "    \n",
    "data_dir = temp_dir+ \"/minst\"\n",
    "ray_dir = temp_dir + \"ray/tune/results\"\n",
    "# Download data\n",
    "MNISTDataModule(data_dir=data_dir).prepare_data()\n",
    "\n",
    "os.environ['MPLCONFIGDIR'] = ray_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6566a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f1f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05-10-2022\n",
      "05-10-2022-RAY-wadkars-MLFlow-Demo-Git\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jwt\n",
    "import json\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time_str = now.strftime(\"%m-%d-%Y\")\n",
    "print(date_time_str)\n",
    "experiment_name = date_time_str+'-'+'RAY'+'-' + os.environ['DOMINO_STARTING_USERNAME'] + '-' + os.environ['DOMINO_PROJECT_NAME']\n",
    "model_name = 'RAY'+'-' + os.environ['DOMINO_PROJECT_NAME']\n",
    "\n",
    "token = os.environ['MLFLOW_TRACKING_TOKEN']\n",
    "\n",
    "#os.environ['AWS_ACCESS_KEY_ID']=config['AWS_ACCESS_KEY_ID']\n",
    "#os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS_SECRET_ACCESS_KEY']\n",
    "print(experiment_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb82400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-domino-artifacts-946429944765/wadkars/', experiment_id='40', lifecycle_stage='active', name='05-10-2022-RAY-wadkars-MLFlow-Demo-Git', tags={'domino.project': 'MLFlow-Demo-Git',\n",
       " 'mlflow.domino.project': 'MLFlow-Demo-Git',\n",
       " 'mlflow.domino.project_id': '6246ebecd2cb0975f43db262',\n",
       " 'mlflow.domino.project_identity': 'wadkars/MLFlow-Demo-Git',\n",
       " 'mlflow.domino.user': 'wadkars'}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(exp)\n",
    "if(exp == None):\n",
    "  mlflow.create_experiment(experiment_name)  \n",
    "mlflow.set_experiment(experiment_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34266529",
   "metadata": {},
   "source": [
    "## MLFlow Setup Code\n",
    "\n",
    "Configure MLFlow connection & setup a experiment and Ray tune experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "035db7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "from ray import tune\n",
    " \n",
    "# Change this to 1 if you want each training run to use 1 GPU.\n",
    "num_gpus_per_run = 0\n",
    " \n",
    "# Specify the hyperparameter search space.\n",
    "# Tune will resolve this search space, and pass in the config to your training function.\n",
    "config = {\n",
    "        \"layer_1\": tune.choice([32, 64, 128]),\n",
    "        \"layer_2\": tune.choice([64, 128, 256]),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([32, 64, 128]),\n",
    "        # Make sure to pass in the mlflow configurations. The token does not need to be passed in if not running on Databricks.\n",
    "        \"mlflow\": {\n",
    "            \"experiment_name\": experiment_name,\n",
    "            \"tracking_uri\": mlflow.get_tracking_uri(),\n",
    "            \"token\": token\n",
    "        },\n",
    "        \"data_dir\": data_dir,\n",
    "        \"num_epochs\": 5,\n",
    "        \"num_gpus\": num_gpus_per_run,\n",
    "        \"AWS_ACCESS_KEY_ID\": os.environ['AWS_ACCESS_KEY_ID'],\n",
    "        \"AWS_SECRET_ACCESS_KEY\": os.environ['AWS_SECRET_ACCESS_KEY'],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6c5d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hyperparam tunning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Matplotlib created a temporary config/cache directory at /tmp/matplotlib-bog1qgz5 because the default path (/home/ray/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m 2022-05-09 18:50:13,834\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:50:14 (running for 00:00:00.17)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 4.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 PENDING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-------+--------------+-----------+-----------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc   |   batch_size |   layer_1 |   layer_2 |          lr |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-------+--------------+-----------+-----------+-------------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | PENDING  |       |           32 |       128 |       256 | 0.000101428 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | PENDING  |       |           64 |       128 |       256 | 0.000144632 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-------+--------------+-----------+-----------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=78, ip=10.0.54.3)\u001b[0m Matplotlib created a temporary config/cache directory at /tmp/matplotlib-tc37ec58 because the default path (/home/ray/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=350)\u001b[0m Matplotlib created a temporary config/cache directory at /tmp/matplotlib-271zedof because the default path (/home/ray/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.classification.accuracy.Accuracy`. It will be removed in v1.5.0.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m   stream(template_mgs % msg_args)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m   | Name     | Type     | Params\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m --------------------------------------\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 0 | layer_1  | Linear   | 100 K \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 1 | layer_2  | Linear   | 33.0 K\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 2 | layer_3  | Linear   | 2.6 K \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 3 | accuracy | Accuracy | 0     \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m --------------------------------------\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 136 K     Trainable params\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 136 K     Total params\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 0.544     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:50:20 (running for 00:00:06.25)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.2/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.classification.accuracy.Accuracy`. It will be removed in v1.5.0.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m   stream(template_mgs % msg_args)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m   | Name     | Type     | Params\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m --------------------------------------\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 0 | layer_1  | Linear   | 100 K \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 1 | layer_2  | Linear   | 33.0 K\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 2 | layer_3  | Linear   | 2.6 K \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 3 | accuracy | Accuracy | 0     \n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m --------------------------------------\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 136 K     Trainable params\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 136 K     Total params\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 0.544     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:50:25 (running for 00:00:11.30)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:50:30 (running for 00:00:16.30)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00001:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-50-31\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: f451065974e9454f82604f10a4fb61a7\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-head-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.62.136\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 350\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 11.732851505279541\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 11.732851505279541\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 11.732851505279541\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147431\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00001\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.9025930762290955\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.3393193781375885\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py:102: LightningDeprecationWarning: The signature of `Callback.on_train_epoch_end` has changed in v1.3. `outputs` parameter has been removed. Support for the old signature will be removed in v1.5\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m   warning_cache.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:50:35 (running for 00:00:22.03)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.3393193781375885 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |        |                  |            |           |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      1 |          11.7329 |   0.339319 |  0.902593 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00000:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-50-37\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: 530a3ac69087456487061b4d3231cfda\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.54.3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 78\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 17.815531969070435\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 17.815531969070435\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 17.815531969070435\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147437\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00000\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.9002500176429749\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.33918261528015137\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py:102: LightningDeprecationWarning: The signature of `Callback.on_train_epoch_end` has changed in v1.3. `outputs` parameter has been removed. Support for the old signature will be removed in v1.5\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m   warning_cache.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:50:41 (running for 00:00:27.57)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00000 with val_loss=0.33918261528015137 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00010142773885177127, 'batch_size': 32, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      1 |          17.8155 |   0.339183 |  0.90025  |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      1 |          11.7329 |   0.339319 |  0.902593 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00001:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-50-43\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: f451065974e9454f82604f10a4fb61a7\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-head-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 2\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.62.136\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 350\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 23.049892902374268\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 11.317041397094727\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 23.049892902374268\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147443\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00001\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.919298529624939\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.2815455198287964\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:50:47 (running for 00:00:33.34)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.2815455198287964 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      1 |          17.8155 |   0.339183 |  0.90025  |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      2 |          23.0499 |   0.281546 |  0.919299 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:50:52 (running for 00:00:38.34)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.2815455198287964 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      1 |          17.8155 |   0.339183 |  0.90025  |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      2 |          23.0499 |   0.281546 |  0.919299 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00001:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-50-54\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: f451065974e9454f82604f10a4fb61a7\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-head-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.62.136\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 350\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 34.18075442314148\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 11.130861520767212\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 34.18075442314148\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147454\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00001\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.9306017160415649\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.239767923951149\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:50:57 (running for 00:00:43.48)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.239767923951149 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      1 |          17.8155 |   0.339183 |  0.90025  |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      3 |          34.1808 |   0.239768 |  0.930602 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00000:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-50-57\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: 530a3ac69087456487061b4d3231cfda\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 2\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.54.3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 78\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 37.838778257369995\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 20.02324628829956\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 37.838778257369995\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147457\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00000\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.9223333597183228\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.27456095814704895\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:02 (running for 00:00:48.59)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.239767923951149 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      2 |          37.8388 |   0.274561 |  0.922333 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      3 |          34.1808 |   0.239768 |  0.930602 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00001:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-51-05\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: f451065974e9454f82604f10a4fb61a7\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-head-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 4\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.62.136\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 350\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 45.5183789730072\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 11.337624549865723\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 45.5183789730072\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147465\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00001\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.939660906791687\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.21076370775699615\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:07 (running for 00:00:53.78)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.21076370775699615 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      2 |          37.8388 |   0.274561 |  0.922333 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      4 |          45.5184 |   0.210764 |  0.939661 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:12 (running for 00:00:58.78)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.21076370775699615 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      2 |          37.8388 |   0.274561 |  0.922333 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      4 |          45.5184 |   0.210764 |  0.939661 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00000:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-51-14\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: 530a3ac69087456487061b4d3231cfda\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.54.3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 78\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 54.83411169052124\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 16.995333433151245\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 54.83411169052124\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147474\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00000\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.9292500019073486\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.24043066799640656\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00001:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-51-17\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: f451065974e9454f82604f10a4fb61a7\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-head-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 5\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.62.136\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 350\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 57.073434591293335\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 11.555055618286133\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 57.073434591293335\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147477\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00001\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.9472240805625916\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.1854718029499054\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:18 (running for 00:01:04.33)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      3 |          54.8341 |   0.240431 |  0.92925  |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 2022/05/09 18:51:18 WARNING mlflow.utils.requirements_utils: Found torch version (1.9.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torch==1.9.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 2022/05/09 18:51:19 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.10.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torchvision==0.10.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:23 (running for 00:01:09.34)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.8/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      3 |          54.8341 |   0.240431 |  0.92925  |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=350)\u001b[0m 2022/05/09 18:51:26 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.10.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torchvision==0.10.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:28 (running for 00:01:14.37)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 5.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status   | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING  | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      3 |          54.8341 |   0.240431 |  0.92925  |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | RUNNING  | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+----------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00000:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-51-30\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: 530a3ac69087456487061b4d3231cfda\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 4\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.54.3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 78\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 71.3225908279419\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 16.488479137420654\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 71.3225908279419\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147490\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00000\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.937583327293396\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.2167685478925705\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00001:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-51-17\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: f451065974e9454f82604f10a4fb61a7\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_tag: 1_batch_size=64,layer_1=128,layer_2=256,lr=0.00014463\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-head-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 5\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.62.136\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 350\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 57.073434591293335\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 11.555055618286133\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 57.073434591293335\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147477\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00001\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.9472240805625916\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.1854718029499054\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:33 (running for 00:01:20.06)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 4.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status     | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING    | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      4 |          71.3226 |   0.216769 |  0.937583 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | TERMINATED | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:39 (running for 00:01:25.11)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 4.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status     | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING    | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      4 |          71.3226 |   0.216769 |  0.937583 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | TERMINATED | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:44 (running for 00:01:30.11)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 4.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status     | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING    | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      4 |          71.3226 |   0.216769 |  0.937583 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | TERMINATED | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00000:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-51-47\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: 530a3ac69087456487061b4d3231cfda\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 5\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.54.3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 78\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 87.70380687713623\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 16.381216049194336\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 87.70380687713623\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147507\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00000\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.9444166421890259\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.19185864925384521\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 2022/05/09 18:51:49 WARNING mlflow.utils.requirements_utils: Found torch version (1.9.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torch==1.9.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 2022/05/09 18:51:49 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.10.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torchvision==0.10.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:49 (running for 00:01:35.48)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 4.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status     | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING    | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      5 |          87.7038 |   0.191859 |  0.944417 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | TERMINATED | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:54 (running for 00:01:40.49)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 4.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status     | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING    | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      5 |          87.7038 |   0.191859 |  0.944417 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | TERMINATED | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=78, ip=10.0.54.3)\u001b[0m 2022/05/09 18:51:56 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.10.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torchvision==0.10.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:51:59 (running for 00:01:45.52)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 4.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status     | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | RUNNING    | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      5 |          87.7038 |   0.191859 |  0.944417 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | TERMINATED | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result for train_mnist_tune_88b51_00000:\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   date: 2022-05-09_18-51-47\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_id: 530a3ac69087456487061b4d3231cfda\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   experiment_tag: 0_batch_size=32,layer_1=128,layer_2=256,lr=0.00010143\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   hostname: ray-6279c402d2cb0975f43e8426-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   iterations_since_restore: 5\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   node_ip: 10.0.54.3\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   pid: 78\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_since_restore: 87.70380687713623\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_this_iter_s: 16.381216049194336\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   time_total_s: 87.70380687713623\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timestamp: 1652147507\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   trial_id: 88b51_00000\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_acc: 0.9444166421890259\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   val_loss: 0.19185864925384521\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current time: 2022-05-09 18:52:01 (running for 00:01:47.62)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Memory usage on this node: 4.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/5.12 GiB heap, 0.0/2.36 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Current best trial: 88b51_00001 with val_loss=0.1854718029499054 and parameters={'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Result logdir: /mnt/data/MLFlow-Demo-Git/ray/tune/results/tune_mnist\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m Number of trials: 2/2 (2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | Trial name                   | status     | loc             |   batch_size |   layer_1 |   layer_2 |          lr |   iter |   total time (s) |   val_loss |   val_acc |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m |------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------|\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00000 | TERMINATED | 10.0.54.3:78    |           32 |       128 |       256 | 0.000101428 |      5 |          87.7038 |   0.191859 |  0.944417 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m | train_mnist_tune_88b51_00001 | TERMINATED | 10.0.62.136:350 |           64 |       128 |       256 | 0.000144632 |      5 |          57.0734 |   0.185472 |  0.947224 |\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m +------------------------------+------------+-----------------+--------------+-----------+-----------+-------------+--------+------------------+------------+-----------+\n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m \n",
      "Best hyperparameters found were:  {'layer_1': 128, 'layer_2': 256, 'lr': 0.00014463186376048476, 'batch_size': 64, 'mlflow': {'experiment_name': '05-10-2022-RAY-wadkars-MLFlow-Demo-Git', 'tracking_uri': 'http://mlflow-dev.mlflow-dev.svc.cluster.local:5000/', 'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkb21pbm9fYXBpX2tleSI6ImUxNDI3MGE5NzM3YzFlYmM0MTM2MDA1OTU2ZGI2OWM2ZTBmNGVhZjkzZWE4OTUzZmRmZDE3ODI3MTU2YjdjYTUiLCJkb21pbm9fcHJvamVjdF9uYW1lIjoiTUxGbG93LURlbW8tR2l0IiwiZG9taW5vX3J1bl9pZCI6IjYyNzljNDAyZDJjYjA5NzVmNDNlODQyNiIsInRhZ3MiOnt9fQ.DgTObb4HEEap3ps6JVEEwL3HDTESbfwWntf3wZXw0DE'}, 'data_dir': '/mnt/data//MLFlow-Demo-Git//minst', 'num_epochs': 5, 'num_gpus': 0, 'AWS_ACCESS_KEY_ID': 'AKIA5YW464O6ZEC6YZZA', 'AWS_SECRET_ACCESS_KEY': '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'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=217)\u001b[0m 2022-05-09 18:52:01,701\tINFO tune.py:626 -- Total run time: 107.87 seconds (107.59 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "print('Running hyperparam tunning...')\n",
    "\n",
    "analysis = tune.run(\n",
    "        train_mnist_tune,\n",
    "        local_dir=ray_dir,\n",
    "        resources_per_trial={\n",
    "            \"cpu\": 1,\n",
    "            \"gpu\": num_gpus_per_run\n",
    "        },\n",
    "        metric=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        config=config,\n",
    "        # How many different samples to try from the hyperparameter search space?\n",
    "        num_samples=2,\n",
    "        name=\"tune_mnist\")\n",
    " \n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9873c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78913e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb0298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eedfcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c780e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
